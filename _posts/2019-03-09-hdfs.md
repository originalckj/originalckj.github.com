---
layout: post
comments: true
title: Hadoop의 이해
category: [ Lab ]
---

### HDFS
* HDFS는 Hadoop Distributed File System 약자로 흔히 알고 있는 FAT, NTFS 등과 같은 OS에서 제공하는 파일시스템과 크게 다르지 않다.  
실제 데이터를 저장하는 *블럭(block)* 과 데이터 블럭의 메타정보를 관리하는 *메타데이터(meta)* 로 구성되어 있다.
* HDFS의 구조는 *NameNode, DataNode, JournalNode* 3가지의 Node로 구성
* NameNode의 역할은 수백 ~ 수천만 개에 이르는 데이터 블럭들에 대한 조회를 실시간으로 처리하기 위해 메타 정보를 메모리에 들고 있다.
* DataNode의 역할은 데이터 블럭을 읽고 쓰는 것이다.
* JournalNode의 역할은 블럭들에 대한 이력(Journal)들을 관리한다.
* Hadoop 2.0 버전에서는 NameNode 2대로 구성한 *HA(High Availability)* 지원한다.
* Hadoop 1.0 버전에 있던 Secondary NameNode 대신 *Active, Standby NameNode* 존재한다.

#### HDFS 기동 절차
1. Hadoop 관련된 환경 설정 값들을 읽어온다. (호스트 이름, IP Address, 라이브러리 저장 경로, JDK 버전 등)  
2. NameNode를 메타 정보를 구성하는 fsimage 스냅샷과 edits 로그를 모두 메모리에 올린다.    
이 때, fsimage를 읽어들이기 직전에 in_use.lock 파일을 먼저 생성하여 파일시스템에 잠금을 설정한다.   
`FsImage: 디스크에 저장되어 있던 마지막 스냅샷`  
`Edit Log: 스냅샷을 찍은 이후의 변경 로그`  
3. NameNode 메모리에 메타정보가 모두 반영되면 SafeMode 진입 후,   
NameNode의 자원을 점검하고 블럭정보를 조사하여 최소한의 블럭 replication 만족하는지 확인한다.  
4. HA 구성이 되어 있다면, Standby NameNode를 기동한다.   
Standby NameNode는 edit 로그를 관리하는 JournalNode 에서 받은 edit 로그를 fsimage에 반영하여 일정 주기로  
active NameNode로 전달하여 fsimage를 갱신하는 역할을 수행한다.
5. DataNode들이 등록을 시도한다. 자신이 관리하는 데이터 블럭들을 스캔하고 이 정보를 NameNode로 보고한다.  
NameNode는 fsimage로 부터 읽어온 메타정보는 블럭 자체의 메타정보만 갖고 있고, 이 블럭이 어느 DataNode에 위치하는지는 알 수가 없다.
DataNode들이 등록을 하면서 블럭에 대한 위치정보를 보고함으로써 메타정보와 매핑을 시도한다. 
6. NameNode는 SafeMode에서 벗어나 정상적인 HDFS 서비스를 제공한다
  
`블럭 매핑 정보는 fsimage 혹은 edits에 저장되지 않으며 오직 메모리에만 유지된다.`  
`fsimage는 파일블록, 블록크기, 복제요소, 엑세스 시간, 수정시간, 파일권한 같은 정보를 보유`


#### FailOver
1. HA로 구성된 두 대의 NameNode는 Standby 모드로 시작한다.   
두 대 모두 정상적으로 Standby로 시작하면, HAAdmin 클래스는 그 중 한비에 FailOver 명령을 내린다.
2. FailOver 명령을 받은 Standby NameNode는 active 모드로 전환된다.
3. Standby 자격으로 연결했던 JournalNode와 연결을 종료 후, Active 자격으로 새롭게 연결한다.
4. active NameNode는 블럭정보의 변화를 Edit Log에 기록을 해야하기 때문이다.

`Standby NameNode는 JournalNode로 부터 Edit 로그를 받아야 한다.`  


### NameNode
![_config.yml]({{ site.baseurl }}/assets/lab/2019-03-09/2019-03-09_name.png)
* 위 그림은 NameNode 디렉터리 구성이다.
* 네임노드는 fsimage, edits 로 구성되어 있으며 메타정보를 NameNode 메모리에 올려 기동한다.
* fsimage와 edits로 구성되어 있는 이유는 메타데이터의 스냅샷인 fsimage는 성능 상의 이유로 자주 만들 수가 없다. 
대신 마지막 스냅샷을 완성 후의 변경 내역들은 edits 로그라는 상대적으로 작은 크기의 파일로 기록하고 이 edits 로그를 주기적으로
fsimage에 반영하는 방법으로 스냅샷을 유지한다.

#### Filename format
* 완성된 edits 파일 네임 포맷: edits_{start transaction ID}-{end transaction ID}
* 진행중 edits 파일 네임 포맷: edits_inprogress_{transaction ID}
* fsimage 파일 네임 포맷: fsimage_{end transaction ID}

#### edits
* standby NameNode는 완성된 edits 파일 로그만 읽을 수 있다.
* standby NameNode는 진행 중인 edits 파일을 쓸 수 없다.
* 완성된 edits 파일과 진행 중 edits 파일 둘 다 갖고 있는 이유는   
failover로 인해 standby가 active로 변경되거나 active가 standby로 변경될 수 있기 때문이다.

#### seen_txid
* senn_txid가 갖고 있는 정보는 edits_inprogress의 transaction ID 값이다.
* NameNode가 메타정보를 가져올 때, fsimage와 완성된 edits 로그를 가져옴과 동시에 진행 중인 edits 로그도 가져오도록 한다.
  
참조  
<https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_hdfs-administration/content/hdfs_metadata_namenodes.html>

### DataNode
![_config.yml]({{ site.baseurl }}/assets/lab/2019-03-09/2019-03-09_data.png)
#### finalized / rbw
* 블록 저장을 위한 디렉터리
* finalized는 복제본 작성이 완성된 블럭을 갖고 있다.
* rbw는 'replica being written' 약자로 복제본 작성 중인 블럭을 갖고 있다. 

참조  
<https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_hdfs-administration/content/hdfs_metadata_datanodes.html>

### JournalNode
* NameNode와 같이 in-memory 방식의 솔루션들은 데이터의 영속성과 성능 사이의 트레이드 오프가 중요하다.  
이 문제를 해결하기 위해 전체 메타데이터의 스냅샷 이 후 새롭게 발생하는 메타데이터의 변화를 edit 라는 로그파일에 기록하는 방법을 쓴다.  
일정한 주기(2분 마다) 계속 롤링되는 이 Edits 관리하는 데몬을 JournalNode라고 부른다.

#### committed-txid
* NameNode으로 커밋된 마지막 transaction Id 값이다.

#### last-promised-epoch
* NameNode가 새롭게 시작되면, epoch 숫자를 증가시켜 JournalNode에 전달한다.  
* JournalNode가 갖고 있는 epoch 값 보다 낮을 경우 무시해야 brain split 시나리오를 방지할 수 있다.  

`brain split: HA로 구성된 두 개의 NameNode가 장애로 인해 서로 active NameNode가 되어 충돌이 발생되는 경우`

#### last-writer-epoch
* 마지막으로 작성한 transaction epoch 숫자를 갖고 있다. 

참조  
<https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_hdfs-administration/content/hdfs_metadata_journalnodes.html>
